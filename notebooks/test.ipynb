{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd73dc46",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'video_processor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvideo_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoProcessor, merge_video_audio\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maudiocraft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VidMuse\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'video_processor'"
     ]
    }
   ],
   "source": [
    "from video_processor import VideoProcessor, merge_video_audio\n",
    "from audiocraft.models import VidMuse\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd8ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the video\n",
    "video_path = 'sample.mp4'\n",
    "# Initialize the video processor\n",
    "processor = VideoProcessor()\n",
    "# Process the video to obtain tensors and duration\n",
    "local_video_tensor, global_video_tensor, duration = processor.process(video_path)\n",
    "\n",
    "progress = True\n",
    "USE_DIFFUSION = False\n",
    "\n",
    "# Load the pre-trained VidMuse model\n",
    "MODEL = VidMuse.get_pretrained('HKUSTAudio/VidMuse')\n",
    "# Set generation parameters for the model based on video duration\n",
    "MODEL.set_generation_params(duration=duration)\n",
    "\n",
    "try:\n",
    "    # Generate outputs using the model\n",
    "    outputs = MODEL.generate([local_video_tensor, global_video_tensor], progress=progress, return_tokens=USE_DIFFUSION)\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "# Detach outputs from the computation graph and convert to CPU float tensor\n",
    "outputs = outputs.detach().cpu().float()\n",
    "\n",
    "\n",
    "sampling_rate = 32000\n",
    "output_wav_path = \"vidmuse_sample.wav\"\n",
    "# Write the output audio data to a WAV file\n",
    "scipy.io.wavfile.write(output_wav_path, rate=sampling_rate, data=outputs[0, 0].numpy())\n",
    "\n",
    "output_video_path = \"vidmuse_sample.mp4\"\n",
    "# Merge the original video with the generated music\n",
    "merge_video_audio(video_path, output_wav_path, output_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9094676",
   "metadata": {},
   "source": [
    "### Missing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe1819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e83eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidmuse",
   "language": "python",
   "name": "vidmuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
